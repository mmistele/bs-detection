{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Lambda,Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9908\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = read_csv('data/train-big.csv') \n",
    "X_test, Y_test = read_csv('data/test_minus_dev_big.csv') \n",
    "# small \n",
    "X_dev, Y_dev = read_csv('data/dev_big.csv')\n",
    "\n",
    "\n",
    "ratio=0.1\n",
    "total_train_num=len(X_train)\n",
    "train_num = int(ratio * total_train_num)\n",
    "train_index=(np.random.random([train_num])*total_train_num).astype(int)\n",
    "print (train_num)\n",
    "\n",
    "X_train=X_train[train_index]\n",
    "Y_train = Y_train[train_index]\n",
    "\n",
    "\n",
    "maxLen = len(max(X_train, key=len).split())+10\n",
    "print(maxLen)\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w not in word_to_index:\n",
    "                X_indices[i, j] = 0 # HACK - FIX SOON\n",
    "            else:\n",
    "                if j >= maxLen:\n",
    "                    print (sentence_words)\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "    return X_indices\n",
    "\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"lemon\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim)) # curious why not transpose of this...\n",
    "    # Sets each row \"index\" of the embedding matrix to be \n",
    "    # the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix]) # now it's pretrained!\n",
    "\n",
    "    return embedding_layer\n",
    "\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "X_dev_indices = sentences_to_indices(X_dev, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model_V1(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Model-V1 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_indices = Input(shape = input_shape, dtype = np.int32)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "\n",
    "    # Propagates sentence_indices through the embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "\n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    LSTM1 = LSTM(128, return_sequences = True,name='LSTM1')(embeddings)\n",
    "    # Adds dropout with probability 0.5\n",
    "    X = Dropout(0.5)(LSTM1)\n",
    "    # Another LSTM layer, but just returns one output\n",
    "    LSTM2 = LSTM(128, return_sequences = True, name='LSTM2')(X)\n",
    "    \n",
    "    def get_last(X):\n",
    "        return X[:,-1,:]\n",
    "    \n",
    "    LSTM2Last = Lambda(get_last, name='LSTM2-last')(LSTM2)\n",
    "    Dropout2 = Dropout(0.5,name='Dropout2')(LSTM2Last)\n",
    "    \n",
    "    # Propagating through a Dense layer with sigmoid activation to get back a scalar\n",
    "    Dense1 = Dense(1,name='Dense1')(Dropout2)\n",
    "    X = Activation('sigmoid',name='output_layer')(Dense1)\n",
    "\n",
    "    model = Model(inputs = sentence_indices, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_V2(input_shape, word_to_vec_map, word_to_index,num_layer,num_cell,dropout_ratio,bidirectional):\n",
    "    \"\"\"\n",
    "    Function creating the Model-V1 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_indices = Input(shape = input_shape, dtype = np.int32)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "\n",
    "    # Propagates sentence_indices through the embedding layer\n",
    "    X = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # add the first layer, if there is any.\n",
    "    if num_layer == 2:\n",
    "        print (2)\n",
    "        # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "        if bidirectional == True:\n",
    "            print ('b1')\n",
    "            LSTM1 = Bidirectional(LSTM(num_cell, return_sequences = True),name='LSTM1')(X)\n",
    "        else:\n",
    "            print('l1')\n",
    "            LSTM1 = LSTM(num_cell, return_sequences = True,name='LSTM1')(X)\n",
    "        # Adds dropout with probability 0.5\n",
    "        X = Dropout(dropout_ratio)(LSTM1)\n",
    "\n",
    "    # add second layer (or the only layer)\n",
    "    if  num_layer == 1 and bidirectional == True:\n",
    "        print ('b2')\n",
    "        LSTM2 = Bidirectional(LSTM(num_cell, return_sequences = True), name='LSTM2')(X)\n",
    "    else:\n",
    "        print ('l2')\n",
    "    # Another LSTM layer, but just returns one output\n",
    "        LSTM2 = LSTM(num_cell, return_sequences = True, name='LSTM2')(X)\n",
    "    \n",
    "    def get_last(X):\n",
    "        return X[:,-1,:]\n",
    "    \n",
    "    LSTM2Last = Lambda(get_last, name='LSTM2-last')(LSTM2)\n",
    "    Dropout2 = Dropout(dropout_ratio,name='Dropout2')(LSTM2Last)\n",
    "    \n",
    "    # Propagating through a Dense layer with sigmoid activation to get back a scalar\n",
    "    Dense1 = Dense(1,name='Dense1')(Dropout2)\n",
    "    X = Activation('sigmoid',name='output_layer')(Dense1)\n",
    "\n",
    "    model = Model(inputs = sentence_indices, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "num_layer=[1] # index 0 is better\n",
    "num_cell=[64] # 0 index\n",
    "drop_ratio=[0.3] # 2 index\n",
    "bidirectional=[False] # 0 index\n",
    "\n",
    "# optimizer\n",
    "beta1=0.9\n",
    "beta2=0.999\n",
    "\n",
    "#fitting\n",
    "learning_rate=[0.001]#[0.001,0.002,0.003,0.004]\n",
    "batch_size=[300]#[5,10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2\n",
      "Train on 9908 samples, validate on 184 samples\n",
      "Epoch 1/20\n",
      "9908/9908 [==============================] - 14s 1ms/step - loss: 0.6925 - acc: 0.5078 - val_loss: 0.6962 - val_acc: 0.4348\n",
      "Epoch 2/20\n",
      "9908/9908 [==============================] - 2s 212us/step - loss: 0.6804 - acc: 0.5665 - val_loss: 0.7254 - val_acc: 0.5326\n",
      "Epoch 3/20\n",
      "9908/9908 [==============================] - 2s 212us/step - loss: 0.6350 - acc: 0.6434 - val_loss: 0.5294 - val_acc: 0.7663\n",
      "Epoch 4/20\n",
      "9908/9908 [==============================] - 2s 213us/step - loss: 0.5866 - acc: 0.6941 - val_loss: 0.4518 - val_acc: 0.8261\n",
      "Epoch 5/20\n",
      "9908/9908 [==============================] - 2s 212us/step - loss: 0.5566 - acc: 0.7173 - val_loss: 0.4469 - val_acc: 0.8098\n",
      "Epoch 6/20\n",
      "9908/9908 [==============================] - 2s 219us/step - loss: 0.5203 - acc: 0.7458 - val_loss: 0.5512 - val_acc: 0.7446\n",
      "Epoch 7/20\n",
      "9908/9908 [==============================] - 2s 215us/step - loss: 0.5257 - acc: 0.7427 - val_loss: 0.4303 - val_acc: 0.8261\n",
      "Epoch 8/20\n",
      "9908/9908 [==============================] - 2s 232us/step - loss: 0.4815 - acc: 0.7737 - val_loss: 0.4249 - val_acc: 0.7935\n",
      "Epoch 9/20\n",
      "9908/9908 [==============================] - 2s 214us/step - loss: 0.4615 - acc: 0.7808 - val_loss: 0.4110 - val_acc: 0.8043\n",
      "Epoch 10/20\n",
      "9908/9908 [==============================] - 2s 211us/step - loss: 0.4365 - acc: 0.7987 - val_loss: 0.4419 - val_acc: 0.7826\n",
      "Epoch 11/20\n",
      "9908/9908 [==============================] - 2s 211us/step - loss: 0.4315 - acc: 0.7983 - val_loss: 0.2962 - val_acc: 0.8587\n",
      "Epoch 12/20\n",
      "9908/9908 [==============================] - 2s 214us/step - loss: 0.3994 - acc: 0.8201 - val_loss: 0.3564 - val_acc: 0.8370\n",
      "Epoch 13/20\n",
      "9908/9908 [==============================] - 2s 217us/step - loss: 0.3799 - acc: 0.8313 - val_loss: 0.3010 - val_acc: 0.8641\n",
      "Epoch 14/20\n",
      "9908/9908 [==============================] - 2s 218us/step - loss: 0.3669 - acc: 0.8359 - val_loss: 0.4095 - val_acc: 0.7935\n",
      "Epoch 15/20\n",
      "9908/9908 [==============================] - 2s 229us/step - loss: 0.3650 - acc: 0.8397 - val_loss: 0.2428 - val_acc: 0.9022\n",
      "Epoch 16/20\n",
      "9908/9908 [==============================] - 2s 233us/step - loss: 0.3466 - acc: 0.8501 - val_loss: 0.4552 - val_acc: 0.8098\n",
      "Epoch 17/20\n",
      "9908/9908 [==============================] - 2s 224us/step - loss: 0.3523 - acc: 0.8465 - val_loss: 0.2486 - val_acc: 0.8967\n",
      "Epoch 18/20\n",
      "9908/9908 [==============================] - 2s 232us/step - loss: 0.3290 - acc: 0.8592 - val_loss: 0.3920 - val_acc: 0.8098\n",
      "Epoch 19/20\n",
      "9908/9908 [==============================] - 2s 230us/step - loss: 0.3571 - acc: 0.8414 - val_loss: 0.2481 - val_acc: 0.8641\n",
      "Epoch 20/20\n",
      "9908/9908 [==============================] - 2s 239us/step - loss: 0.2875 - acc: 0.8788 - val_loss: 0.2138 - val_acc: 0.9076\n",
      "1663/1663 [==============================] - 0s 222us/step\n",
      "Test accuracy =  0.8863499699696962\n"
     ]
    }
   ],
   "source": [
    "il=0\n",
    "ic=0\n",
    "idr=0\n",
    "ibr=0\n",
    "# might want to change the metric here\n",
    "model = Model_V2((maxLen,), word_to_vec_map, word_to_index,num_layer[il],num_cell[ic],drop_ratio[idr],bidirectional[ibr])\n",
    "optimizer = Adam(lr=learning_rate[ilr], beta_1=beta1, beta_2=beta2, decay=0.0, epsilon=None)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# train the model\n",
    "model_fitting = model.fit(X_train_indices, Y_train, epochs = 20, batch_size = batch_size[ibs], shuffle=True,validation_data=(X_dev_indices, Y_dev))\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "model.save('word_model_PB.h5')\n",
    "print(\"Test accuracy = \", acc)\n",
    "val_acc[il][ic][idr][ibr][ilr][ibs] = model_fitting.history['val_acc'][-1]\n",
    "tra_acc[il][ic][idr][ibr][ilr][ibs] = model_fitting.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[0.8414 ,0.9076]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for il in range(len(num_layer)):\n",
    "    for ic in range(len(num_cell)):\n",
    "        for idr in range(len(drop_ratio)):\n",
    "            for ibr in range(len(bidirectional)):\n",
    "                for ilr in range(len(learning_rate)):\n",
    "                    for ibs in range(len(batch_size)):\n",
    "                        print ('num_layer:'+str(num_layer[il]),'num_cell:'+str(num_cell[ic]),'drop_ratio:'+str(drop_ratio[idr]),'bidirectional:'+str(bidirectional[ibr]))\n",
    "                        print('val_acc'+str(val_acc[il][ic][idr][ibr][ilr][ibs]),'tra_acc'+str(tra_acc[il][ic][idr][ibr][ilr][ibs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc=np.zeros([len(num_layer),len(num_cell),len(drop_ratio),len(bidirectional),len(learning_rate),len(batch_size)])\n",
    "tra_acc=np.zeros([len(num_layer),len(num_cell),len(drop_ratio),len(bidirectional),len(learning_rate),len(batch_size)])\n",
    "for il in range(len(num_layer)):\n",
    "    for ic in range(len(num_cell)):\n",
    "        for idr in range(len(drop_ratio)):\n",
    "            for ibr in range(len(bidirectional)):\n",
    "                for ilr in range(len(learning_rate)):\n",
    "                    for ibs in range(len(batch_size)):\n",
    "                        # might want to change the metric here\n",
    "                        model = Model_V2((maxLen,), word_to_vec_map, word_to_index,num_layer[il],num_cell[ic],drop_ratio[idr],bidirectional[ibr])\n",
    "                        optimizer = Adam(lr=learning_rate[ilr], beta_1=beta1, beta_2=beta2, decay=0.0, epsilon=None)\n",
    "                        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "                        # train the model\n",
    "                        model_fitting = model.fit(X_train_indices, Y_train, epochs = 20, batch_size = batch_size[ibs], shuffle=True,validation_data=(X_dev_indices, Y_dev))\n",
    "                        loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "                        model.save('my_model.h5')\n",
    "                        print(\"Test accuracy = \", acc)\n",
    "                        val_acc[il][ic][idr][ibr][ilr][ibs] = model_fitting.history['val_acc'][-1]\n",
    "                        tra_acc[il][ic][idr][ibr][ilr][ibs] = model_fitting.history['acc'][-1]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_acc.shape)\n",
    "np.mean(val_acc[:,:,:,:,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_fitting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fcd85ce0fcb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_fitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_fitting' is not defined"
     ]
    }
   ],
   "source": [
    "model_fitting.history['val_acc'][-1]\n",
    "model_fitting.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model, InputSpec\n",
    "from keras.layers import Dense, Activation, Dropout, Lambda\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "from keras.models import load_model\n",
    "model = load_model('word_1lay_64cell_30drop_1dir_60ep_50kex.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_bs(model, include_gradients=False):\n",
    "\n",
    "    LSTM2 = model.get_layer('LSTM2')\n",
    "    Dropout2 = model.get_layer('Dropout2')\n",
    "    output_layer = model.get_layer('output_layer')\n",
    "\n",
    "    inputs = []\n",
    "    inputs.extend(model.inputs)\n",
    "\n",
    "    outputs = []\n",
    "    outputs.extend(model.outputs)\n",
    "    outputs.append(LSTM2.output)\n",
    "    outputs.append(LSTM2.cell.kernel_f)  # -- weights of the forget gates (assuming LSTM)\n",
    "    #print (LSTM1.trainable_weights)\n",
    "\n",
    "    if include_gradients:\n",
    "        loss = K.mean(model.output)  # [batch_size, 1] -> scalar\n",
    "        grads = K.gradients(loss, LSTM2.output)\n",
    "        grads_norm = grads / (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "        outputs.append(grads_norm)\n",
    "\n",
    "    all_function = K.function(inputs, outputs)\n",
    "    output_function = K.function([Dropout2.input], model.outputs)\n",
    "    print(Dropout2.input)\n",
    "    return all_function, output_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightedOutputs(model):\n",
    "\n",
    "    LSTM2 = model.get_layer('LSTM2')\n",
    "    Dense1 = model.get_layer('Dense1')\n",
    "\n",
    "    weightedOutputs = LSTM2.output * Dense1.get_weights()\n",
    "\n",
    "    return K.function(model.inputs, weightedOutputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"LSTM2-last/strided_slice:0\", shape=(?, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_function, output_function = visualize_model_bs(model, include_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) (1, 35, 64) (50, 64) (1, 1, 35, 64)\n",
      "Scores: [[0.5273786]]\n",
      "Time distributed (word-level) scores: [array([[0.5292262 ],\n",
      "       [0.60930586],\n",
      "       [0.7797758 ],\n",
      "       [0.67087257],\n",
      "       [0.57521385],\n",
      "       [0.76162696],\n",
      "       [0.7860274 ],\n",
      "       [0.7751681 ],\n",
      "       [0.7585693 ],\n",
      "       [0.7478044 ],\n",
      "       [0.7440752 ],\n",
      "       [0.5625093 ],\n",
      "       [0.55784297],\n",
      "       [0.5774576 ],\n",
      "       [0.61416   ],\n",
      "       [0.66246104],\n",
      "       [0.71662575],\n",
      "       [0.772387  ],\n",
      "       [0.82495326],\n",
      "       [0.8691724 ],\n",
      "       [0.90199864],\n",
      "       [0.9237125 ],\n",
      "       [0.936372  ],\n",
      "       [0.94181436],\n",
      "       [0.94056755],\n",
      "       [0.9309745 ],\n",
      "       [0.9070768 ],\n",
      "       [0.8525909 ],\n",
      "       [0.7279502 ],\n",
      "       [0.4801502 ],\n",
      "       [0.19076174],\n",
      "       [0.0457784 ],\n",
      "       [0.00930508],\n",
      "       [0.5273786 ],\n",
      "       [0.5273786 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sentence=\"I like the way you think think think think think think\"\n",
    "t = np.array([sentence])\n",
    "X = sentences_to_indices(t, word_to_index, maxLen)\n",
    "# -- Return scores, raw rnn values and gradients\n",
    "# scores is equivalent to model.predict(X)\n",
    "scores, rnn_values, rnn_gradients, W_i = all_function([X])\n",
    "print(scores.shape, rnn_values.shape, rnn_gradients.shape, W_i.shape)\n",
    "\n",
    "# -- score prediction\n",
    "print(\"Scores:\", scores)\n",
    "\n",
    "# -- Return scores at each step in the time sequence\n",
    "time_distributed_scores = map(lambda x: output_function([x]), rnn_values)\n",
    "print(\"Time distributed (word-level) scores:\", map(lambda x: x[0], time_distributed_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;0m0\u001b[48;5;1m1\u001b[48;5;2m2\u001b[48;5;3m3\u001b[48;5;4m4\u001b[48;5;5m5\u001b[48;5;6m6\u001b[48;5;7m7\u001b[48;5;8m8\u001b[48;5;9m9\u001b[48;5;10m10\u001b[48;5;11m11\u001b[48;5;12m12\u001b[48;5;13m13\u001b[48;5;14m14\u001b[48;5;15m15\u001b[48;5;16m16\u001b[48;5;17m17\u001b[48;5;18m18\u001b[48;5;19m19\u001b[48;5;20m20\u001b[48;5;21m21\u001b[48;5;22m22\u001b[48;5;23m23\u001b[48;5;24m24\u001b[48;5;25m25\u001b[48;5;26m26\u001b[48;5;27m27\u001b[48;5;28m28\u001b[48;5;29m29\u001b[48;5;30m30\u001b[48;5;31m31\u001b[48;5;32m32\u001b[48;5;33m33\u001b[48;5;34m34\u001b[48;5;35m35\u001b[48;5;36m36\u001b[48;5;37m37\u001b[48;5;38m38\u001b[48;5;39m39\u001b[48;5;40m40\u001b[48;5;41m41\u001b[48;5;42m42\u001b[48;5;43m43\u001b[48;5;44m44\u001b[48;5;45m45\u001b[48;5;46m46\u001b[48;5;47m47\u001b[48;5;48m48\u001b[48;5;49m49\u001b[48;5;50m50\u001b[48;5;51m51\u001b[48;5;52m52\u001b[48;5;53m53\u001b[48;5;54m54\u001b[48;5;55m55\u001b[48;5;56m56\u001b[48;5;57m57\u001b[48;5;58m58\u001b[48;5;59m59\u001b[48;5;60m60\u001b[48;5;61m61\u001b[48;5;62m62\u001b[48;5;63m63\u001b[48;5;64m64\u001b[48;5;65m65\u001b[48;5;66m66\u001b[48;5;67m67\u001b[48;5;68m68\u001b[48;5;69m69\u001b[48;5;70m70\u001b[48;5;71m71\u001b[48;5;72m72\u001b[48;5;73m73\u001b[48;5;74m74\u001b[48;5;75m75\u001b[48;5;76m76\u001b[48;5;77m77\u001b[48;5;78m78\u001b[48;5;79m79\u001b[48;5;80m80\u001b[48;5;81m81\u001b[48;5;82m82\u001b[48;5;83m83\u001b[48;5;84m84\u001b[48;5;85m85\u001b[48;5;86m86\u001b[48;5;87m87\u001b[48;5;88m88\u001b[48;5;89m89\u001b[48;5;90m90\u001b[48;5;91m91\u001b[48;5;92m92\u001b[48;5;93m93\u001b[48;5;94m94\u001b[48;5;95m95\u001b[48;5;96m96\u001b[48;5;97m97\u001b[48;5;98m98\u001b[48;5;99m99\u001b[48;5;100m100\u001b[48;5;101m101\u001b[48;5;102m102\u001b[48;5;103m103\u001b[48;5;104m104\u001b[48;5;105m105\u001b[48;5;106m106\u001b[48;5;107m107\u001b[48;5;108m108\u001b[48;5;109m109\u001b[48;5;110m110\u001b[48;5;111m111\u001b[48;5;112m112\u001b[48;5;113m113\u001b[48;5;114m114\u001b[48;5;115m115\u001b[48;5;116m116\u001b[48;5;117m117\u001b[48;5;118m118\u001b[48;5;119m119\u001b[48;5;120m120\u001b[48;5;121m121\u001b[48;5;122m122\u001b[48;5;123m123\u001b[48;5;124m124\u001b[48;5;125m125\u001b[48;5;126m126\u001b[48;5;127m127\u001b[48;5;128m128\u001b[48;5;129m129\u001b[48;5;130m130\u001b[48;5;131m131\u001b[48;5;132m132\u001b[48;5;133m133\u001b[48;5;134m134\u001b[48;5;135m135\u001b[48;5;136m136\u001b[48;5;137m137\u001b[48;5;138m138\u001b[48;5;139m139\u001b[48;5;140m140\u001b[48;5;141m141\u001b[48;5;142m142\u001b[48;5;143m143\u001b[48;5;144m144\u001b[48;5;145m145\u001b[48;5;146m146\u001b[48;5;147m147\u001b[48;5;148m148\u001b[48;5;149m149\u001b[48;5;150m150\u001b[48;5;151m151\u001b[48;5;152m152\u001b[48;5;153m153\u001b[48;5;154m154\u001b[48;5;155m155\u001b[48;5;156m156\u001b[48;5;157m157\u001b[48;5;158m158\u001b[48;5;159m159\u001b[48;5;160m160\u001b[48;5;161m161\u001b[48;5;162m162\u001b[48;5;163m163\u001b[48;5;164m164\u001b[48;5;165m165\u001b[48;5;166m166\u001b[48;5;167m167\u001b[48;5;168m168\u001b[48;5;169m169\u001b[48;5;170m170\u001b[48;5;171m171\u001b[48;5;172m172\u001b[48;5;173m173\u001b[48;5;174m174\u001b[48;5;175m175\u001b[48;5;176m176\u001b[48;5;177m177\u001b[48;5;178m178\u001b[48;5;179m179\u001b[48;5;180m180\u001b[48;5;181m181\u001b[48;5;182m182\u001b[48;5;183m183\u001b[48;5;184m184\u001b[48;5;185m185\u001b[48;5;186m186\u001b[48;5;187m187\u001b[48;5;188m188\u001b[48;5;189m189\u001b[48;5;190m190\u001b[48;5;191m191\u001b[48;5;192m192\u001b[48;5;193m193\u001b[48;5;194m194\u001b[48;5;195m195\u001b[48;5;196m196\u001b[48;5;197m197\u001b[48;5;198m198\u001b[48;5;199m199\u001b[48;5;200m200\u001b[48;5;201m201\u001b[48;5;202m202\u001b[48;5;203m203\u001b[48;5;204m204\u001b[48;5;205m205\u001b[48;5;206m206\u001b[48;5;207m207\u001b[48;5;208m208\u001b[48;5;209m209\u001b[48;5;210m210\u001b[48;5;211m211\u001b[48;5;212m212\u001b[48;5;213m213\u001b[48;5;214m214\u001b[48;5;215m215\u001b[48;5;216m216\u001b[48;5;217m217\u001b[48;5;218m218\u001b[48;5;219m219\u001b[48;5;220m220\u001b[48;5;221m221\u001b[48;5;222m222\u001b[48;5;223m223\u001b[48;5;224m224\u001b[48;5;225m225\u001b[48;5;226m226\u001b[48;5;227m227\u001b[48;5;228m228\u001b[48;5;229m229\u001b[48;5;230m230\u001b[48;5;231m231\u001b[48;5;232m232\u001b[48;5;233m233\u001b[48;5;234m234\u001b[48;5;235m235\u001b[48;5;236m236\u001b[48;5;237m237\u001b[48;5;238m238\u001b[48;5;239m239\u001b[48;5;240m240\u001b[48;5;241m241\u001b[48;5;242m242\u001b[48;5;243m243\u001b[48;5;244m244\u001b[48;5;245m245\u001b[48;5;246m246\u001b[48;5;247m247\u001b[48;5;248m248\u001b[48;5;249m249\u001b[48;5;250m250\u001b[48;5;251m251\u001b[48;5;252m252\u001b[48;5;253m253\u001b[48;5;254m254\n",
      "------Color index:-----\n",
      "\u001b[48;5;196m196\u001b[48;5;197m197\u001b[48;5;198m198\u001b[48;5;205m205\u001b[48;5;212m212\u001b[48;5;219m219\u001b[48;5;225m225\u001b[48;5;231m231\u001b[48;5;229m229\u001b[48;5;193m193\u001b[48;5;192m192\u001b[48;5;191m191\u001b[48;5;155m155\u001b[48;5;154m154\u001b[48;5;82m82"
     ]
    }
   ],
   "source": [
    "# choose the color index\n",
    "from colored import fg, bg, attr\n",
    "min_c=0\n",
    "max_c=255\n",
    "for i in range(min_c,max_c):\n",
    "    print ('%s%s' % (bg (i),str(i)),end=\"\")\n",
    "    \n",
    "print('\\n------Color index:-----')\n",
    "\n",
    "color_index=[196,197,198,205,212,219,225,231,229,193,192,191,155,154,82]\n",
    "for i in color_index:\n",
    "    print ('%s%s' % (bg (i),str(i)),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n",
      "\n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;192mI \u001b[48;5;193mlike \u001b[48;5;229mthe \u001b[48;5;192mway \u001b[48;5;192myou \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;219mthe \u001b[48;5;225mway \u001b[48;5;231myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;205mI \u001b[48;5;225mlike \u001b[48;5;225mthe \u001b[48;5;205mway \u001b[48;5;205myou \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \n",
      "\u001b[48;5;155mI \u001b[48;5;192mlike \u001b[48;5;231mthe \u001b[48;5;225mway \u001b[48;5;212myou \u001b[48;5;229mthink \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;191mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;192mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;193mlike \u001b[48;5;155mthe \u001b[48;5;192mway \u001b[48;5;191myou \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;192mthink \u001b[48;5;193mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;219mI \u001b[48;5;219mlike \u001b[48;5;229mthe \u001b[48;5;212mway \u001b[48;5;212myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;219mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;219mI \u001b[48;5;225mlike \u001b[48;5;225mthe \u001b[48;5;219mway \u001b[48;5;212myou \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \n",
      "\u001b[48;5;192mI \u001b[48;5;154mlike \u001b[48;5;193mthe \u001b[48;5;192mway \u001b[48;5;229myou \u001b[48;5;191mthink \u001b[48;5;154mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;219mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;193mway \u001b[48;5;229myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;225mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;191mway \u001b[48;5;193myou \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;219myou \u001b[48;5;219mthink \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;155mI \u001b[48;5;155mlike \u001b[48;5;191mthe \u001b[48;5;155mway \u001b[48;5;155myou \u001b[48;5;191mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;219mlike \u001b[48;5;212mthe \u001b[48;5;225mway \u001b[48;5;231myou \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;229mway \u001b[48;5;229myou \u001b[48;5;229mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;212mlike \u001b[48;5;225mthe \u001b[48;5;225mway \u001b[48;5;219myou \u001b[48;5;198mthink \u001b[48;5;197mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;219mlike \u001b[48;5;229mthe \u001b[48;5;231mway \u001b[48;5;219myou \u001b[48;5;225mthink \u001b[48;5;229mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;212mlike \u001b[48;5;219mthe \u001b[48;5;212mway \u001b[48;5;212myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;192mway \u001b[48;5;192myou \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \n",
      "\u001b[48;5;198mI \u001b[48;5;231mlike \u001b[48;5;154mthe \u001b[48;5;205mway \u001b[48;5;198myou \u001b[48;5;197mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;231mlike \u001b[48;5;231mthe \u001b[48;5;219mway \u001b[48;5;212myou \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;231mlike \u001b[48;5;193mthe \u001b[48;5;229mway \u001b[48;5;193myou \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;191mthink \u001b[48;5;155mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;219mlike \u001b[48;5;219mthe \u001b[48;5;219mway \u001b[48;5;205myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;197mthink \u001b[48;5;197mthink \u001b[48;5;197mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;193mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;193myou \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;229mlike \u001b[48;5;191mthe \u001b[48;5;191mway \u001b[48;5;231myou \u001b[48;5;192mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;191mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;219mway \u001b[48;5;193myou \u001b[48;5;229mthink \u001b[48;5;192mthink \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;154mthink \u001b[48;5;82mthink \n",
      "\u001b[48;5;155mI \u001b[48;5;229mlike \u001b[48;5;225mthe \u001b[48;5;225mway \u001b[48;5;193myou \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;212mlike \u001b[48;5;198mthe \u001b[48;5;231mway \u001b[48;5;192myou \u001b[48;5;154mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;225mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;219mlike \u001b[48;5;231mthe \u001b[48;5;225mway \u001b[48;5;193myou \u001b[48;5;225mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;154mI \u001b[48;5;191mlike \u001b[48;5;225mthe \u001b[48;5;229mway \u001b[48;5;191myou \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \u001b[48;5;82mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;193mlike \u001b[48;5;191mthe \u001b[48;5;192mway \u001b[48;5;191myou \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;229mway \u001b[48;5;229myou \u001b[48;5;231mthink \u001b[48;5;229mthink \u001b[48;5;193mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;191mthink \n",
      "\u001b[48;5;219mI \u001b[48;5;219mlike \u001b[48;5;205mthe \u001b[48;5;197mway \u001b[48;5;197myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;205mthink \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;219mlike \u001b[48;5;212mthe \u001b[48;5;219mway \u001b[48;5;225myou \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \n",
      "\u001b[48;5;205mI \u001b[48;5;197mlike \u001b[48;5;205mthe \u001b[48;5;198mway \u001b[48;5;196myou \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;212mlike \u001b[48;5;231mthe \u001b[48;5;229mway \u001b[48;5;198myou \u001b[48;5;198mthink \u001b[48;5;197mthink \u001b[48;5;198mthink \u001b[48;5;205mthink \u001b[48;5;212mthink \u001b[48;5;219mthink \n",
      "\u001b[48;5;191mI \u001b[48;5;154mlike \u001b[48;5;191mthe \u001b[48;5;192mway \u001b[48;5;155myou \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;155mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \n",
      "\u001b[48;5;193mI \u001b[48;5;229mlike \u001b[48;5;191mthe \u001b[48;5;229mway \u001b[48;5;229myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \n",
      "\u001b[48;5;192mI \u001b[48;5;192mlike \u001b[48;5;229mthe \u001b[48;5;192mway \u001b[48;5;192myou \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \n",
      "\u001b[48;5;154mI \u001b[48;5;229mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;192myou \u001b[48;5;219mthink \u001b[48;5;198mthink \u001b[48;5;197mthink \u001b[48;5;197mthink \u001b[48;5;196mthink \u001b[48;5;196mthink \n",
      "\u001b[48;5;155mI \u001b[48;5;192mlike \u001b[48;5;229mthe \u001b[48;5;219mway \u001b[48;5;198myou \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;231mthink \u001b[48;5;193mthink \u001b[48;5;192mthink \u001b[48;5;155mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;225mlike \u001b[48;5;231mthe \u001b[48;5;219mway \u001b[48;5;219myou \u001b[48;5;219mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;225mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;225mlike \u001b[48;5;219mthe \u001b[48;5;205mway \u001b[48;5;219myou \u001b[48;5;205mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;219mI \u001b[48;5;225mlike \u001b[48;5;212mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;225mthink \u001b[48;5;225mthink \u001b[48;5;219mthink \u001b[48;5;212mthink \u001b[48;5;205mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;193mI \u001b[48;5;229mlike \u001b[48;5;225mthe \u001b[48;5;193mway \u001b[48;5;192myou \u001b[48;5;191mthink \u001b[48;5;155mthink \u001b[48;5;154mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;225mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;231myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;193mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;229mlike \u001b[48;5;155mthe \u001b[48;5;192mway \u001b[48;5;192myou \u001b[48;5;193mthink \u001b[48;5;231mthink \u001b[48;5;225mthink \u001b[48;5;219mthink \u001b[48;5;212mthink \u001b[48;5;205mthink \n",
      "\u001b[48;5;229mI \u001b[48;5;193mlike \u001b[48;5;229mthe \u001b[48;5;193mway \u001b[48;5;191myou \u001b[48;5;192mthink \u001b[48;5;191mthink \u001b[48;5;192mthink \u001b[48;5;192mthink \u001b[48;5;193mthink \u001b[48;5;229mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;225mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;212myou \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \u001b[48;5;231mthink \n",
      "\u001b[48;5;198mI \u001b[48;5;212mlike \u001b[48;5;205mthe \u001b[48;5;212mway \u001b[48;5;205myou \u001b[48;5;205mthink \u001b[48;5;205mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;231mthe \u001b[48;5;231mway \u001b[48;5;229myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;193mthink \u001b[48;5;193mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;212mlike \u001b[48;5;219mthe \u001b[48;5;212mway \u001b[48;5;205myou \u001b[48;5;205mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \u001b[48;5;212mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;191mway \u001b[48;5;82myou \u001b[48;5;154mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;82mthink \u001b[48;5;154mthink \u001b[48;5;154mthink \n",
      "\u001b[48;5;231mI \u001b[48;5;231mlike \u001b[48;5;229mthe \u001b[48;5;229mway \u001b[48;5;229myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;219mI \u001b[48;5;212mlike \u001b[48;5;231mthe \u001b[48;5;225mway \u001b[48;5;205myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \n",
      "\u001b[48;5;225mI \u001b[48;5;219mlike \u001b[48;5;212mthe \u001b[48;5;205mway \u001b[48;5;198myou \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;198mthink \u001b[48;5;205mthink \u001b[48;5;205mthink \n",
      "\u001b[48;5;192mI \u001b[48;5;191mlike \u001b[48;5;192mthe \u001b[48;5;192mway \u001b[48;5;191myou \u001b[48;5;192mthink \u001b[48;5;229mthink \u001b[48;5;225mthink \u001b[48;5;205mthink \u001b[48;5;198mthink \u001b[48;5;197mthink \n",
      "\u001b[48;5;192mI \u001b[48;5;231mlike \u001b[48;5;192mthe \u001b[48;5;193mway \u001b[48;5;229myou \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \u001b[48;5;229mthink \n",
      "\u001b[48;5;212mI \u001b[48;5;212mlike \u001b[48;5;225mthe \u001b[48;5;225mway \u001b[48;5;212myou \u001b[48;5;212mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;219mthink \u001b[48;5;225mthink \n"
     ]
    }
   ],
   "source": [
    "from colored import fg, bg, attr\n",
    "words=sentence.split()\n",
    "\n",
    "rnn_shape=[1, 35, 64]\n",
    "color_index=[196,197,198,205,212,219,225,231,229,193,192,191,155,154,82]\n",
    "len_color=len(color_index)\n",
    "color_weight=np.array(rnn_values)\n",
    "color_weight_range=(max(color_weight.flatten())-min(color_weight.flatten()))\n",
    "color_weight=len_color*(color_weight-min(color_weight.flatten()))/color_weight_range\n",
    "color_weight=color_weight.reshape(rnn_shape)\n",
    "\n",
    "\n",
    "# color tuning\n",
    "min_c=int(min(color_weight.flatten()))\n",
    "max_c=int(max(color_weight.flatten()))\n",
    "print(min_c,max_c)\n",
    "\n",
    "    \n",
    "print(\"\")\n",
    "\n",
    "def clamp(x, minval, maxval):\n",
    "    return max(minval, min(x, maxval))\n",
    "\n",
    "rnn_shape=rnn_values.shape\n",
    "for i in range(rnn_shape[2]):\n",
    "    #for w in range(rnn_shape[2]):\n",
    "    for w in range(len(words)):\n",
    "        idx = clamp(int(color_weight[0,w,i]), 0, len(color_index)-1)\n",
    "        print ('%s%s' % (bg (color_index[idx]),words[w]),end=\"\")\n",
    "        print (' ' ,end=\"\")\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;127mYou\u001b[1m \u001b[48;5;127mdo\u001b[1m \u001b[48;5;128mme\u001b[1m \u001b[48;5;128mwrong\u001b[1m \u001b[48;5;129mvery\u001b[1m \u001b[48;5;129mhave\u001b[1m \u001b[48;5;129ma\u001b[1m \u001b[48;5;129mof\u001b[1m \u001b[48;5;129mmonths\u001b[1m \u001b[48;5;129mimmediate\u001b[1m "
     ]
    }
   ],
   "source": [
    "from colored import fg, bg, attr\n",
    "\n",
    "words=sentence.split()\n",
    "base=124\n",
    "scale=6\n",
    "color_weight=base+np.array(time_distributed_scores).reshape(maxLen)*scale\n",
    "\n",
    "for i in range(len(words)):\n",
    "    print ('%s%s' % (bg (int(color_weight[i])),words[i]),end=\"\")\n",
    "    print ('%s '%attr(1) ,end=\"\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing dev/test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# small \n",
    "X_test, Y_test = read_csv('data/test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# small\n",
    "import pandas as pd\n",
    "dev_ratio=0.1\n",
    "total_test_num=len(X_test_indices)\n",
    "dev_num = int(dev_ratio * len(X_test_indices))\n",
    "X_dev_indices = []\n",
    "print (dev_num)\n",
    "dev_index=(np.random.random([dev_num])*total_test_num).astype(int)\n",
    "\n",
    "X_dev_indices=X_test_indices[dev_index,:]\n",
    "X_dev = X_test[dev_index]\n",
    "Y_dev = Y_test[dev_index]\n",
    "\n",
    "X_test_after_dev=np.delete(X_test,dev_index,0)\n",
    "Y_test_after_dev=np.delete(Y_test,dev_index,0)\n",
    "\n",
    "# test after dev\n",
    "test_after_dev={'X': X_test_after_dev, 'Y': Y_test_after_dev}\n",
    "test_after_dev = pd.DataFrame(test_after_dev)\n",
    "test_after_dev.to_csv('test_minus_dev.csv',header=False,index=False)\n",
    "\n",
    "# dev\n",
    "dev={'X': X_dev, 'Y': Y_dev}\n",
    "dev = pd.DataFrame(dev)\n",
    "dev.to_csv('dev.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# big\n",
    "X_test, Y_test = read_csv('data/test-big.csv')\n",
    "\n",
    "# small\n",
    "import pandas as pd\n",
    "dev_ratio=0.1\n",
    "total_test_num=len(X_test_indices)\n",
    "dev_num = int(dev_ratio * len(X_test_indices))\n",
    "X_dev_indices = []\n",
    "print (dev_num)\n",
    "dev_index=(np.random.random([dev_num])*total_test_num).astype(int)\n",
    "\n",
    "X_dev_indices=X_test_indices[dev_index,:]\n",
    "X_dev = X_test[dev_index]\n",
    "Y_dev = Y_test[dev_index]\n",
    "\n",
    "X_test_after_dev=np.delete(X_test,dev_index,0)\n",
    "Y_test_after_dev=np.delete(Y_test,dev_index,0)\n",
    "\n",
    "# test after dev\n",
    "test_after_dev={'X': X_test_after_dev, 'Y': Y_test_after_dev}\n",
    "test_after_dev = pd.DataFrame(test_after_dev)\n",
    "test_after_dev.to_csv('test_minus_dev_big.csv',header=False,index=False)\n",
    "\n",
    "# dev\n",
    "dev={'X': X_dev, 'Y': Y_dev}\n",
    "dev = pd.DataFrame(dev)\n",
    "dev.to_csv('dev_big.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9908\n"
     ]
    }
   ],
   "source": [
    "# big\n",
    "X_train, Y_train = read_csv('data/train-big.csv')\n",
    "\n",
    "# small\n",
    "import pandas as pd\n",
    "ratio=0.1\n",
    "total_train_num=len(X_train)\n",
    "train_num = int(ratio * total_train_num)\n",
    "print (train_num)\n",
    "train_index=(np.random.random([train_num])*total_train_num).astype(int)\n",
    "\n",
    "X_train=X_train[train_index]\n",
    "Y_train = Y_train[train_index]\n",
    "\n",
    "\n",
    "# train \n",
    "X_train_shrink={'X': X_train, 'Y': Y_train}\n",
    "X_train_shrink = pd.DataFrame(X_train_shrink)\n",
    "X_train_shrink.to_csv('train_shrink.csv',sep=',',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy history during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_acc_percentage=np.array(model_fitting.history['acc'][:20])*100\n",
    "history_dev_percentage=np.array(model_fitting.history['val_acc'][:20])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAGsCAYAAACxXj05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3e8c88210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10.5, 6.5)\n",
    "\n",
    "word_train,=plt.plot(history_acc_percentage, linewidth=2,color='blue',linestyle='-',label='Word model train acc')\n",
    "word_dev,=plt.plot(history_dev_percentage, linewidth=2,color='blue',linestyle='--',label='Word model dev acc')\n",
    "plt.xlabel('# of Epoch',fontsize=16)\n",
    "plt.ylabel('Accuracy (%)',fontsize=16)\n",
    "plt.title('Accuracy Improvement',fontsize=16)\n",
    "plt.legend(handles=[word_train,word_dev],fontsize=12,loc=4)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('test2png.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4914"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
